{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78709c59-ed1b-4543-a2bd-c12414173258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76a56ae-3f9c-487f-a8e2-c55e04dc6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"records/*/*trials.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48338e50-ce60-4974-9366-fd28223843b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parzen_files = [f for f in csv_files if \"parzen_sampler\" in f]\n",
    "grid_files   = [f for f in csv_files if \"grid_sampler\" in f]\n",
    "random_files = [f for f in csv_files if \"random_sampler\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c2a5f9-395d-40af-adf2-16e91340bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(file_list):\n",
    "    data_dict = {}\n",
    "    for f in file_list:\n",
    "        # Extract the middle portion: records/<key>/<file>\n",
    "        key = os.path.basename(os.path.dirname(f))  # <--- folder name\n",
    "        if \"parzen_sampler\" in key:\n",
    "            data_dict[key.replace(\"_parzen_sampler\", \"\")] = pd.read_csv(f)\n",
    "        elif \"grid_sampler\" in key:\n",
    "            data_dict[key.replace(\"_grid_sampler\", \"\")] = pd.read_csv(f)\n",
    "        elif \"random_sampler\" in key:\n",
    "            data_dict[key.replace(\"_random_sampler\", \"\")] = pd.read_csv(f)\n",
    "    return data_dict\n",
    "\n",
    "# Build dictionaries\n",
    "parzen_dict = make_dict(parzen_files)\n",
    "grid_dict   = make_dict(grid_files)\n",
    "random_dict = make_dict(random_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933b2ba0-db7b-4484-9938-2f9f45c1e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizs import plot_efficiency_curves_best_of_N, plot_ard_panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3681e895-2927-4f2d-9854-ddfdacb8612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_efficiency_curves_best_of_N(parzen_dict, grid_dict, random_dict, exp_ks=(1,2,4,8,16,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1070f54-ce86-487e-8931-ad21a401f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ard_panels(parzen_dict, grid_dict, random_dict, n_boot=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74895cb3-129c-46c4-9871-a1f5c6ef9004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sbn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, math, json, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import optuna\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def set_seed(seed:int):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "@dataclass\n",
    "class PrepResult:\n",
    "    X: np.ndarray\n",
    "    preproc: str\n",
    "    info: dict\n",
    "\n",
    "def preprocess(trial, X: np.ndarray) -> PrepResult:\n",
    "    choice = trial.suggest_categorical('preproc', ['raw','colnorm','pca'])\n",
    "    info = {}\n",
    "    Xp = X\n",
    "    if choice == 'colnorm':\n",
    "        thresh = trial.suggest_float('colnorm_thresh', 1e-9, 1e-3, log=True)\n",
    "        std = X.std(axis=0, ddof=0)\n",
    "        mask = std > thresh\n",
    "        if mask.sum() == 0:\n",
    "            mask = np.ones_like(std, dtype=bool)\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "        Xp = scaler.fit_transform(X[:, mask])\n",
    "        info.update({'thresh': float(thresh), 'kept': int(mask.sum())})\n",
    "    elif choice == 'pca':\n",
    "        energy = trial.suggest_float('pca_energy', 0.5, 1.0)\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "        Xs = scaler.fit_transform(X)\n",
    "        pca = PCA(n_components=energy, svd_solver='full')\n",
    "        Xp = pca.fit_transform(Xs)\n",
    "        info.update({'energy': float(energy), 'n_components': int(getattr(pca, \"n_components_\", Xp.shape[1]))})\n",
    "    else:\n",
    "        pass\n",
    "    return PrepResult(X=Xp, preproc=choice, info=info)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Model\n",
    "# ---------------------------\n",
    "class OneHiddenMLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hid:int, n_out:int, activation:str,\n",
    "                 dist:str, scale_heur:str, scale_mult: Optional[float]):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid, bias=True)\n",
    "        self.cl = nn.Linear(n_hid, n_hid, bias=False)\n",
    "        self.fc2 = nn.Linear(n_hid, n_out, bias=True)\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            self.act = nn.Tanh()\n",
    "        elif activation == 'logistic':\n",
    "            self.act = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(activation)\n",
    "\n",
    "        # zero-init final layer (zero_softmax analogue)\n",
    "        nn.init.zeros_(self.fc2.weight); nn.init.zeros_(self.fc2.bias)\n",
    "\n",
    "        # initialize first layer per requested heuristic/distribution\n",
    "        if scale_heur == 'Glorot':\n",
    "            nn.init.xavier_uniform_(self.fc1.weight) if dist == 'uniform' else nn.init.xavier_normal_(self.fc1.weight)\n",
    "        elif scale_heur == 'old':\n",
    "            fan_in = n_in\n",
    "            s = (scale_mult if scale_mult is not None else 1.0) / math.sqrt(max(1.0, fan_in))\n",
    "            if dist == 'uniform':\n",
    "                nn.init.uniform_(self.fc1.weight, -s, s)\n",
    "            else:\n",
    "                nn.init.normal_(self.fc1.weight, 0.0, s)\n",
    "        else:\n",
    "            raise ValueError(scale_heur)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.act(self.fc1(x))\n",
    "        c = self.cl(h)\n",
    "        return self.fc2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562b802-76bb-4c84-a9ab-2f96febbe560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sbn]",
   "language": "python",
   "name": "conda-env-sbn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
